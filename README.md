# ğŸ¤ Live Audio Chat with Web Search

A real-time audio chat interface powered by **Gemini 2.0 Flash** with **automatic web search capabilities**. Ask questions about current events, weather, news, or anything - the AI automatically searches the web when needed and responds with up-to-date information.

## âœ¨ Features

- ğŸ¤ **Live Audio Chat** - Real-time voice conversation with AI
- ğŸ” **Automatic Web Search** - AI automatically searches Google for current information
- ğŸ“° **Current Events** - Get today's headlines and breaking news
- ğŸŒ¤ï¸ **Weather Updates** - Real-time weather conditions anywhere
- ğŸ“ˆ **Stock Information** - Current market data and prices
- âš½ **Sports Results** - Latest scores and game results
- ğŸ¯ **Smart Detection** - AI knows when to search vs. use general knowledge
- ğŸ”Š **Natural Voice** - High-quality audio responses with Orus voice

## ğŸš€ Quick Start

### Prerequisites
- **Node.js** (v18 or higher)
- **Gemini API Key** ([Get one here](https://ai.google.dev/))

### Installation

1. **Clone and install dependencies:**
   ```bash
   git clone <your-repo>
   cd live-audio-transcript
   npm install
   ```

2. **Set up your API key:**
   ```bash
   # Add your Gemini API key to .env.local
   echo "GEMINI_API_KEY=your_api_key_here" > .env.local
   ```

3. **Start the development server:**
   ```bash
   npm run dev
   ```

4. **Open your browser:**
   ```
   http://localhost:3003
   ```

5. **Start talking!** ğŸ¤
   - Click the microphone button
   - Ask questions like "What are today's headlines?"
   - The AI will automatically search the web and respond

## ğŸ“ Project Structure

```
live-audio-transcript/
â”œâ”€â”€ ğŸ“„ index.tsx                # Main audio chat component
â”œâ”€â”€ ğŸ“„ index.html               # Application entry point
â”œâ”€â”€ ğŸ“„ utils.ts                 # Audio processing utilities
â”œâ”€â”€ ğŸ“„ index.css                # Application styles
â”œâ”€â”€ ğŸ“„ vite.config.ts           # Vite build configuration
â”œâ”€â”€ ğŸ“„ tsconfig.json            # TypeScript configuration
â”œâ”€â”€ ğŸ“„ package.json             # Dependencies and scripts
â”œâ”€â”€ ğŸ“„ .env.local               # Environment variables (API key)
â”œâ”€â”€ ğŸ“ public/                  # Static assets
â”œâ”€â”€ ğŸ“ test/                    # Test files and examples
â”‚   â”œâ”€â”€ ğŸ“„ gemini-search.ts     # Web search utilities (for testing)
â”‚   â”œâ”€â”€ ğŸ“„ test-search.js       # Basic functionality tests
â”‚   â”œâ”€â”€ ğŸ“„ verify-integration.js # Integration verification
â”‚   â”œâ”€â”€ ğŸ“„ enhanced-audio-with-search.tsx # Alternative component
â”‚   â””â”€â”€ ğŸ“„ README.md            # Test documentation
â””â”€â”€ ğŸ“ docs/                    # Project documentation
```

### ğŸ“„ File Descriptions

#### **Core Application Files**

- **`index.tsx`** - The main React component that handles:
  - Live audio recording and playback
  - Real-time transcription
  - Web search integration via Gemini grounding tools
  - Audio session management

- **`index.html`** - HTML entry point that loads the audio component

- **`utils.ts`** - Audio processing utilities:
  - Audio encoding/decoding functions
  - Blob creation for audio data
  - Audio buffer management

- **`vite.config.ts`** - Build configuration:
  - Environment variable exposure
  - Development server settings
  - Build optimization

#### **Configuration Files**

- **`.env.local`** - Environment variables (your Gemini API key)
- **`tsconfig.json`** - TypeScript compiler configuration
- **`package.json`** - Project dependencies and npm scripts

#### **Test & Development Files**

- **`test/gemini-search.ts`** - Standalone web search utilities for testing
- **`test/verify-integration.js`** - Verifies the web search integration works
- **`test/enhanced-audio-with-search.tsx`** - Alternative component with search toggle

## ğŸ› ï¸ Available Scripts

```bash
# Development
npm run dev              # Start development server (port 3003)
npm run build           # Build for production
npm run preview         # Preview production build

# Testing
npm run test:search     # Test basic web search functionality
npm run test:integration # Verify audio chat integration
npm run test:debug      # Debug grounding issues
npm run test:grounding  # Test different configurations
```

## ğŸ¯ How It Works

### **The Magic Behind the Scenes**

1. **You speak** â†’ Microphone captures your voice
2. **Live session** â†’ Audio sent to Gemini 2.0 Flash in real-time
3. **AI analysis** â†’ Gemini determines if web search is needed
4. **Auto search** â†’ If needed, Google Search is triggered automatically
5. **Smart response** â†’ AI combines search results with its knowledge
6. **Audio output** â†’ You hear the response with current information

### **Web Search Integration**

The web search is built into the live audio session configuration:

```typescript
config: {
  responseModalities: [Modality.AUDIO],
  speechConfig: {
    voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Orus' } }
  },
  inputAudioTranscription: {},
  outputAudioTranscription: {},
  tools: [{
    googleSearch: {}  // â† This enables automatic web search!
  }]
}
```

### **Smart Query Detection**

The AI automatically knows when to search:

**âœ… Uses Web Search:**
- "What are today's headlines?"
- "What's the weather in New York?"
- "Who won the Euro 2024?"
- "What's Apple's current stock price?"

**âŒ Uses General Knowledge:**
- "How do I cook pasta?"
- "Explain quantum physics"
- "Tell me a joke"

## ğŸ”§ Technical Details

### **Technologies Used**
- **Frontend:** TypeScript, Lit Elements, Vite
- **AI:** Google Gemini 2.0 Flash with live audio
- **Web Search:** Google Search grounding tools
- **Audio:** Web Audio API, real-time processing

### **Key Dependencies**
- `@google/genai` - Gemini AI SDK
- `lit` - Web components framework
- `vite` - Build tool and dev server

### **Browser Requirements**
- Modern browser with Web Audio API support
- Microphone access permission
- HTTPS (required for microphone in production)

## ğŸ¤ Usage Examples

### **Current Events**
> "What are the top news stories today?"

*AI searches Google and provides current headlines*

### **Weather**
> "What's the weather like in San Francisco right now?"

*AI gets real-time weather data*

### **Sports**
> "Did the Lakers win their last game?"

*AI searches for recent game results*

### **General Questions**
> "How does photosynthesis work?"

*AI uses general knowledge (no web search needed)*

## ğŸš€ Deployment

### **Build for Production**
```bash
npm run build
```

### **Deploy to Vercel/Netlify**
1. Connect your repository
2. Set `GEMINI_API_KEY` environment variable
3. Deploy!

### **Environment Variables**
```bash
GEMINI_API_KEY=your_gemini_api_key_here
```

## ğŸ§ª Testing

Run the test suite to verify everything works:

```bash
# Verify the integration
npm run test:integration

# Test basic search functionality
npm run test:search

# Debug any issues
npm run test:debug
```

## ğŸ“ License

This project is licensed under the Apache 2.0 License.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ†˜ Troubleshooting

### **Common Issues**

**"I am unable to access the internet"**
- Ensure `tools: [{ googleSearch: {} }]` is in your session config
- Check your API key is valid
- Verify you're using a supported model

**No audio output**
- Check browser microphone permissions
- Ensure HTTPS in production
- Verify Web Audio API support

**Build errors**
- Run `npm install` to ensure dependencies
- Check Node.js version (v18+ required)
- Verify TypeScript configuration

### **Getting Help**

1. Check the test files in `/test/` for examples
2. Run `npm run test:debug` to diagnose issues
3. Review the console for error messages

---

**Ready to chat with AI about anything? Start the app and ask away!** ğŸ¤âœ¨
